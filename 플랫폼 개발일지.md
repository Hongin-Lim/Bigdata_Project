# 플랫폼 개발일지


#### < 1주차 >

- 쿠버네티스 컨테이너디 환경 세팅 ( 완료 )
- ELK 설치 ( 완료 )
- 파이프라인 시나리오 작성 ( 진행중 ) 
- 카프카 올리기 ( 완료 )
- 하둡 이미지 빌드하기 ( 완료 )
- 하둡 이미지 위에 스파크 올려서 이미지 빌드하기 ( 완료 )
- 하둡 + 스파크 이미지 올리기 ( 완료 )
- 하둡 + 스파크 이미지 위에 제플린 올려서 이미지 빌드하기 ( 완료 )
- 하둡 + 스파크 + 제플린 이미지 사용해서 디플로이먼트 올리기 ( 완료 )
- 쿠버네티스 디플로이먼트 포트포워딩 고려 ( 추후과제 )
- 프로그램 개발환경 테스트 ( 진행중 )
- 프로그램들 모두 연결하기 ( 추후과제 )
- 쿠버네티스 컨테이너 기능들 추가해보기 ( 보류 )




**2022 / 05 / 03**

- Containerd 설치
- Kubernetes 설치

	master node 1대  
	worker node 5대

	master 172.30.1.222  
	worker1 172.30.1.2  
	worker2 172.30.1.62  
	worker3 172.30.1.129  
	worker4 172.30.1.144  
	worker5 172.30.1.194  

▶ 오늘의 오류 발생 및 해결 과정
	
	1. calico node 0/1 문제 발생
		: 방화벽 문제인줄 알고 방화벽 해제 했지만 계속 같은 문제 발생
		  → 가상머신 Network를 Bridge로 설정하지 않고 NAT로 한 것이 원인

**2022 / 05 / 04**

- Elasticsearch 설치
- Logstash 설치
- Kibana 설치
- Spark 설치


▶ 오늘의 오류 발생 및 해결 과정

	1. apt install docker.io 설치 오류
		→ apt install containerd 실행하고 다시 apt install docker.io 진행하기

**2022 / 05 / 05**

- Ubuntu 이미지 위에 Hadoop 설치

▶ 오늘의 오류 발생 및 해결 과정

	1. ssh 연결 오류
		→ vi /etc/hosts.allow 파일에 ssh:ALL:allow\sshd:ALL:allow 추가 후
                             service ssh restart 명령어 실행

	2. 도커 이미지 push 시 requeste denied 오류 발생
		→ docker login이 안되어 있거나 이미지 username과 docker hub id가 일치하지 않을 때 발생

**2022 / 05 / 06**

- Ubuntu 이미지 위에 kafka 설치

▶ 오늘의 오류 발생 및 해결 과정

	1. /opt/kafka/bin/zookeeper-server-start.sh config/zookeeper.properties 실행이 안됨
		→ producer와 consumer가 아직 준비 되지 않아서 설치로 끝냄

**2022 / 05 / 07**

- Ubuntu + Hadoop 이미지 위에 Spark 설치

▶ 오늘의 오류 발생 및 해결 과정

	1. bash : start command not found
		→ .bashrc 에 환경변수 설정을 안넣어줘서 발생하는 오류

**2022 / 05 / 08**

- Ubuntu + Hadoop + Spark 이미지 위에 Zepplin 설치

▶ 오늘의 오류 발생 및 해결 과정

	1. wget으로 zeppelin 파일을 다운받을 때 root 디렉토리에 저장하지 않아서 경로 설정에 충돌 발생 

	2. 컨테이너 자체를 접속할 때 포트포워딩을 하고 접속을 하면 되는데 디플로이먼트로 생성 후 포트포워딩을 어떻게 해야할지 생각해보기  





#### < 2주차 >

- 하둡&스파크 / 제플린 컨테이너 분리 ( 진행중 )
- hadoop, spark, zeppelin on k8s 구현 ( 진행중 )
- 카프카 & 로그스태시 연결 ( 진행중 )
- 뉴스 크롤링 데이터를 통한 프로그램 간 데이터 이동 테스트 
- helm 사용하기 (진행중)


**2022 / 05 / 09**

- hadoop, spark clustering 구현 진행중
- Kafka & Logstash 연결
- helm을 프로젝트 환경에 맞게 사용하기 (불필요한 chart 삭제 등, 차지하는 데이터가 많으면 사용 보류)


▶ 오늘의 오류 발생 및 해결 과정

	1. 카프카와 로그스태시 연결 오류
		→ 서로 다른 컨테이너끼리의 연결오류, 같은 네트워크 상에 존재하지 않아서 발생하는 것 같아 보임 ( 아직 정확한 오류 파악 못함 )	
	
	2. hadoop 설치 시 각 노드마다 yaml을 설정해줘야(pod, service 등) 동작하는 것으로 보임
		→ 조금 더 알아보고 
		
**2022 / 05 / 10**

- Kafka 도커 이미지 만들기
- Kafka 이미지를 사용해서 디플로이먼트 생성
- Kafka & Logstash 연결
- hdfs-base 도커 파일 작성 후 도커 이미지 생성, 도커 허브에 배포
- hadoop namenode / datanode / journalnode yaml 파일을 프로젝트에 맞게 수정, 작성

▶ 오늘의 오류 발생 및 해결 과정

	1. 로그스태시 실행 시 카프카 컨테이너에 접근할 수 없다는 오류
		→ 카프카안에 conf 파일들에 localhost:9092 로 되어있는 것들을 카프카 컨테이너의 ip 와 부여받은 포트로 변경시도 172.30.1.129:30901

	2. vi /etc/hosts 안에 카프카 파드 ip와 워커노드 ip 중 어떤 것을 사용해야하는지 모르겠다.
		→ 172번대 ip ( 워커노드 ip ) 아닌 198번대 ip ( 컨테이너 ip )로 logstash.conf 파일을 실행시키니깐 오류의 반복은 사라짐 (  Error connecting to node kafka-797db9cb6f-tsjxt:9092 (id: 0 rack: null) )
		→ 하지만, disconnect 문제가 발생함 (  Bootstrap broker 192.168.182.14:9092 (id: -1 rack: null) disconnected )
	3. 도커파일, yaml파일을 프로젝트에 맞게 수정하는 과정 중 문제
		→ 도커파일 : 참고 자료에서는 debian 기반이라 프로젝트에 맞게(ubuntu) 수정
		→ yaml : service 방식이 달라서 프로젝트에 맞게(metallb) 수정하고 Pod 대신 Deployment로 수정
