# 플랫폼 개발일지


#### < 1주차 >

- 쿠버네티스 컨테이너디 환경 세팅 ( 완료 )
- ELK 설치 ( 완료 )
- 파이프라인 시나리오 작성 ( 진행중 ) 
- 카프카 올리기 ( 완료 )
- 하둡 이미지 빌드하기 ( 완료 )
- 하둡 이미지 위에 스파크 올려서 이미지 빌드하기 ( 완료 )
- 하둡 + 스파크 이미지 올리기 ( 완료 )
- 하둡 + 스파크 이미지 위에 제플린 올려서 이미지 빌드하기 ( 완료 )
- 하둡 + 스파크 + 제플린 이미지 사용해서 디플로이먼트 올리기 ( 완료 )
- 쿠버네티스 디플로이먼트 포트포워딩 고려 ( 추후과제 )
- 프로그램 개발환경 테스트 ( 진행중 )
- 프로그램들 모두 연결하기 ( 추후과제 )
- 쿠버네티스 컨테이너 기능들 추가해보기 ( 보류 )




**2022 / 05 / 03**

- Containerd 설치
- Kubernetes 설치

	master node 1대  
	worker node 5대

	master 172.30.1.222  
	worker1 172.30.1.2  
	worker2 172.30.1.62  
	worker3 172.30.1.129  
	worker4 172.30.1.144  
	worker5 172.30.1.194  

▶ 오늘의 오류 발생 및 해결 과정
	
	1. calico node 0/1 문제 발생
		: 방화벽 문제인줄 알고 방화벽 해제 했지만 계속 같은 문제 발생
		  → 가상머신 Network를 Bridge로 설정하지 않고 NAT로 한 것이 원인

**2022 / 05 / 04**

- Elasticsearch 설치
- Logstash 설치
- Kibana 설치
- Spark 설치


▶ 오늘의 오류 발생 및 해결 과정

	1. apt install docker.io 설치 오류
		→ apt install containerd 실행하고 다시 apt install docker.io 진행하기

**2022 / 05 / 05**

- Ubuntu 이미지 위에 Hadoop 설치

▶ 오늘의 오류 발생 및 해결 과정

	1. ssh 연결 오류
		→ vi /etc/hosts.allow 파일에 ssh:ALL:allow\sshd:ALL:allow 추가 후
                             service ssh restart 명령어 실행

	2. 도커 이미지 push 시 requeste denied 오류 발생
		→ docker login이 안되어 있거나 이미지 username과 docker hub id가 일치하지 않을 때 발생

**2022 / 05 / 06**

- Ubuntu 이미지 위에 kafka 설치

▶ 오늘의 오류 발생 및 해결 과정

	1. /opt/kafka/bin/zookeeper-server-start.sh config/zookeeper.properties 실행이 안됨
		→ producer와 consumer가 아직 준비 되지 않아서 설치로 끝냄

**2022 / 05 / 07**

- Ubuntu + Hadoop 이미지 위에 Spark 설치

▶ 오늘의 오류 발생 및 해결 과정

	1. bash : start command not found
		→ .bashrc 에 환경변수 설정을 안넣어줘서 발생하는 오류

**2022 / 05 / 08**

- Ubuntu + Hadoop + Spark 이미지 위에 Zepplin 설치

▶ 오늘의 오류 발생 및 해결 과정

	1. wget으로 zeppelin 파일을 다운받을 때 root 디렉토리에 저장하지 않아서 경로 설정에 충돌 발생 

	2. 컨테이너 자체를 접속할 때 포트포워딩을 하고 접속을 하면 되는데 디플로이먼트로 생성 후 포트포워딩을 어떻게 해야할지 생각해보기  





#### < 2주차 >

- 하둡&스파크 / 제플린 컨테이너 분리 ( 진행중 )
- hadoop, spark, zeppelin on k8s 구현 ( 진행중 )
- 카프카 & 로그스태시 연결 ( 진행중 )
- 뉴스 크롤링 데이터를 통한 프로그램 간 데이터 이동 테스트 
- helm 사용하기 (진행중)


**2022 / 05 / 09**

- hadoop, spark clustering 구현 진행중
- Kafka & Logstash 연결
- helm을 프로젝트 환경에 맞게 사용하기 (불필요한 chart 삭제 등, 차지하는 데이터가 많으면 사용 보류)


▶ 오늘의 오류 발생 및 해결 과정

	1. 카프카와 로그스태시 연결 오류
		→ 서로 다른 컨테이너끼리의 연결오류, 같은 네트워크 상에 존재하지 않아서 발생하는 것 같아 보임 ( 아직 정확한 오류 파악 못함 )	
	
	2. hadoop 설치 시 각 노드마다 yaml을 설정해줘야(pod, service 등) 동작하는 것으로 보임
		→ 조금 더 알아보고 
